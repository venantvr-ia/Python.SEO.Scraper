# =============================================================================
# Server Configuration
# =============================================================================
HOST=0.0.0.0
PORT=8001

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# =============================================================================
# Crawler Configuration
# =============================================================================
CRAWLER_HEADLESS=true
CRAWLER_VERBOSE=false

# Timeouts (milliseconds)
DEFAULT_TIMEOUT=30000
MIN_TIMEOUT=1000
MAX_TIMEOUT=120000

# Scraping options
WORD_COUNT_THRESHOLD=10
EXCLUDE_EXTERNAL_LINKS=true
# WARNING: true can remove stats/counters styled as overlays
REMOVE_OVERLAY_ELEMENTS=false
PROCESS_IFRAMES=false

# Wait for JS content (SPAs, lazy-loaded counters, animations)
# Delay in seconds after page load before capturing HTML
DELAY_BEFORE_RETURN=2.0
# Optional CSS selector to wait for (e.g., ".stats-loaded")
WAIT_FOR_SELECTOR=

# =============================================================================
# Database
# =============================================================================
DATABASE_PATH=data/scraper.db
MAX_LOGS_RETENTION_DAYS=30

# Database encryption key (SQLCipher)
# Leave empty for unencrypted database
# WARNING: If you enable encryption on an existing database, you must migrate it first
DATABASE_KEY=your-database-encryption-key-here

# =============================================================================
# Concurrency & Retry
# =============================================================================
MAX_CONCURRENT_BROWSERS=5
RETRY_MAX_ATTEMPTS=3
RETRY_MIN_WAIT=1
RETRY_MAX_WAIT=10

# =============================================================================
# CORS
# =============================================================================
CORS_ORIGINS=*
CORS_ALLOW_CREDENTIALS=false

# =============================================================================
# Content Processing Pipeline
# =============================================================================

# Step 1: DOM Pruning - Remove nav, footer, scripts, ads before conversion
ENABLE_DOM_PRUNING=true

# Step 2: Use Trafilatura for main content extraction (more robust than default)
USE_TRAFILATURA=true

# Step 3: Regex cleaning (normalize newlines, remove empty links)
ENABLE_REGEX_CLEANING=true

# Step 4: LLM HTML Sanitizer - AI-powered HTML to Markdown (expensive, bypasses steps 1-3)
ENABLE_LLM_HTML_SANITIZER=false

# Step 5: LLM Structure Sanitizer - AI-powered heading hierarchy fix
ENABLE_LLM_STRUCTURE_SANITIZER=true

# Include images in output (set to false to strip all images)
INCLUDE_IMAGES=true

# =============================================================================
# Gemini API (for LLM Sanitizer)
# =============================================================================
GEMINI_API_KEY=
GEMINI_MODEL=gemini-2.0-flash
GEMINI_TEMPERATURE=0.2
GEMINI_MAX_TOKENS=8192

# Safety threshold: reject LLM output if content loss > this percentage
LLM_MAX_CONTENT_LOSS_PERCENT=10.0

# =============================================================================
# Dashboard & Documentation
# =============================================================================
DASHBOARD_ENABLED=true

# API documentation (disable in production for security)
# Set to false to hide /docs, /redoc, and /openapi.json
DOCS_ENABLED=true

# =============================================================================
# Authentication
# =============================================================================
# API Key for programmatic access (/scrape, /scrape/batch)
# Leave empty to disable API key authentication
API_KEY=your-secret-api-key-here

# Multi-user configuration (JSON format)
# Roles: "admin" (full access), "viewer" (read-only dashboard)
# If USERS is set, ADMIN_USERNAME/ADMIN_PASSWORD are ignored
# Example: [{"username":"admin","password":"secret","role":"admin"},{"username":"reader","password":"pass123","role":"viewer"}]
USERS=

# Legacy: single admin credentials (used only if USERS is empty)
ADMIN_USERNAME=admin
ADMIN_PASSWORD=your-secure-password-here

# Session configuration
SESSION_EXPIRY_DAYS=30
SESSION_SECRET_KEY=generate-a-random-secret-key-here

# =============================================================================
# PDF Processing
# =============================================================================
MAX_PDF_SIZE_MB=50
